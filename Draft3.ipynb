{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1bb6e7d6",
   "metadata": {},
   "source": [
    "Layers of a CNN\n",
    "\n",
    "1. Input Layer - Shape = [batch_size, image_width, image_height, channels]\n",
    "\n",
    "batch_size - random sample from the original training set thats used during applying stochastic gradient descent.\n",
    "channels - number of color channels of the input images. This number could be 3 for RGB images or 1 for binary images.\n",
    "\n",
    "If the dataset is composed of monochrome 28x28 pixel images, then the desired shape for our input layer would be"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eea6426",
   "metadata": {},
   "outputs": [],
   "source": [
    "[batch_size, 28, 28, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb7b8647",
   "metadata": {},
   "source": [
    "To change the shape of the input layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c84762a",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer = tf.reshape(features[\"x\"], [-1, 28, 28, 1])\n",
    "\n",
    "# The batch size is denoted as -1, which means it will be determined dynamically based on the input data. \n",
    "# This allows us to fine-tune the CNN model by trying varying batch sizes during training or inference."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "509234c8",
   "metadata": {},
   "source": [
    "2. Convolutional Step - The main purposeof these convolutional steps is to extract fetaures from the input images then feed them to a linear classifier. The whole idea of stacking convolutional steps is to be able to detect features anywhere in the image.\n",
    "\n",
    "If we wanted to apply 20 filters each of size 5x5 to the input layer with a ReLUactivation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721a51c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_layer_1 = tf.layers.conv2d(\n",
    "  inputs=input_layer,\n",
    "  filters=20,\n",
    "  kernel_size=[5, 5],\n",
    "  padding=\"same\",\n",
    "  activation=tf.nn.relu,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb2f21c5",
   "metadata": {},
   "source": [
    "inputs - represents the input layer defined int he first step\n",
    "filters - specifies the number of filters to be applied to the input image. The higher the number of filters, the more features are extracted from the input image.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
