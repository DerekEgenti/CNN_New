{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1bb6e7d6",
   "metadata": {},
   "source": [
    "Layers of a CNN\n",
    "\n",
    "1. Input Layer - Shape = [batch_size, image_width, image_height, channels]\n",
    "\n",
    "batch_size - random sample from the original training set thats used during applying stochastic gradient descent.\n",
    "channels - number of color channels of the input images. This number could be 3 for RGB images or 1 for binary images.\n",
    "\n",
    "If the dataset is composed of monochrome 28x28 pixel images, then the desired shape for our input layer would be"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eea6426",
   "metadata": {},
   "outputs": [],
   "source": [
    "[batch_size, 28, 28, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb7b8647",
   "metadata": {},
   "source": [
    "To change the shape of the input layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c84762a",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer = tf.reshape(features[\"x\"], [-1, 28, 28, 1])\n",
    "\n",
    "# The batch size is denoted as -1, which means it will be determined dynamically based on the input data. \n",
    "# This allows us to fine-tune the CNN model by trying varying batch sizes during training or inference."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "509234c8",
   "metadata": {},
   "source": [
    "2. Convolutional Step - The main purposeof these convolutional steps is to extract fetaures from the input images then feed them to a linear classifier. The whole idea of stacking convolutional steps is to be able to detect features anywhere in the image.\n",
    "\n",
    "If we wanted to apply 20 filters each of size 5x5 to the input layer with a ReLUactivation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721a51c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_layer_1 = tf.layers.conv2d(\n",
    "  inputs=input_layer,\n",
    "  filters=20,\n",
    "  kernel_size=[5, 5],\n",
    "  padding=\"same\",\n",
    "  activation=tf.nn.relu,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb2f21c5",
   "metadata": {},
   "source": [
    "inputs - represents the input layer defined int he first step\n",
    "filters - specifies the number of filters to be applied to the input image. The higher the number of filters, the more features are extracted from the input image.\n",
    "kernel_size - represents the size of the filter/feature detector\n",
    "padding - we use 'same' here to introduce zero padding to the corner pixels of the input image\n",
    "activation - specifies the fuction to be used for the output of the convolutional opertation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a3a4ac8",
   "metadata": {},
   "source": [
    "Introducing Non-Linearity\n",
    "\n",
    "We talked about feeding the output of the convolution step to an activation function, in this case, ReLU.\n",
    "The ReLU activation function replaces all negative pixel values with zero, this is done to introduce non linearity in the output image , as the data we are using is usually non-linear.\n",
    "\n",
    "Without activation functions, a CNN (or any neural network) would only be able to learn linear relationships between inputs and outputs, no matter how many layers it has. Real-world data, however—like images, audio, and text—often involve complex, non-linear patterns. Activation functions allow the network to model these complex relationships."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc4e0bb3",
   "metadata": {},
   "source": [
    "The Pooling Step - This step is mainly for reducing dimensionality by reducung the size of the feature map (the result map from the covolutional step) while keeping the important information in the newly reduced version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8745d6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can connect the output of the first convolutional layer to the pooling layer by using the following code:\n",
    "pooling_layer_1 = tf.layers.max_pooling2d(\n",
    "  inputs=conv_layer_1,\n",
    "  pool_size=[2, 2],\n",
    "  strides=2)\n",
    "# The pooling layer reduces the spatial dimensions of the input, which helps to reduce the number of parameters and computation in the network.\n",
    "\n",
    "# The pooling layer receives the input from the convolutional step with the following shape:\n",
    "[batch_size, image_height, image_width, channels]\n",
    "\n",
    "# that is.........\n",
    "\n",
    "[batch_size, 28, 28, 20]"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
