{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1bb6e7d6",
   "metadata": {},
   "source": [
    "Layers of a CNN\n",
    "\n",
    "**Input Layer**\n",
    "\n",
    "Shape = [batch_size, image_width, image_height, channels]\n",
    "\n",
    "batch_size - random sample from the original training set thats used during applying stochastic gradient descent.\n",
    "channels - number of color channels of the input images. This number could be 3 for RGB images or 1 for binary images.\n",
    "\n",
    "If the dataset is composed of monochrome 28x28 pixel images, then the desired shape for our input layer would be"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eea6426",
   "metadata": {},
   "outputs": [],
   "source": [
    "[batch_size, 28, 28, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb7b8647",
   "metadata": {},
   "source": [
    "To change the shape of the input layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c84762a",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer = tf.reshape(features[\"x\"], [-1, 28, 28, 1])\n",
    "\n",
    "# The batch size is denoted as -1, which means it will be determined dynamically based on the input data. \n",
    "# This allows us to fine-tune the CNN model by trying varying batch sizes during training or inference."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "509234c8",
   "metadata": {},
   "source": [
    "**2. Convolutional Step**\n",
    "\n",
    "The main purposeof these convolutional steps is to extract fetaures from the input images then feed them to a linear classifier. The whole idea of stacking convolutional steps is to be able to detect features anywhere in the image.\n",
    "\n",
    "If we wanted to apply 20 filters each of size 5x5 to the input layer with a ReLUactivation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721a51c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_layer_1 = tf.layers.conv2d(\n",
    "  inputs=input_layer,\n",
    "  filters=20,\n",
    "  kernel_size=[5, 5],\n",
    "  padding=\"same\",\n",
    "  activation=tf.nn.relu,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb2f21c5",
   "metadata": {},
   "source": [
    "inputs - represents the input layer defined int he first step\n",
    "filters - specifies the number of filters to be applied to the input image. The higher the number of filters, the more features are extracted from the input image.\n",
    "kernel_size - represents the size of the filter/feature detector\n",
    "padding - we use 'same' here to introduce zero padding to the corner pixels of the input image\n",
    "activation - specifies the fuction to be used for the output of the convolutional opertation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a3a4ac8",
   "metadata": {},
   "source": [
    "Introducing Non-Linearity\n",
    "\n",
    "We talked about feeding the output of the convolution step to an activation function, in this case, ReLU.\n",
    "The ReLU activation function replaces all negative pixel values with zero, this is done to introduce non linearity in the output image , as the data we are using is usually non-linear.\n",
    "\n",
    "Without activation functions, a CNN (or any neural network) would only be able to learn linear relationships between inputs and outputs, no matter how many layers it has. Real-world data, however—like images, audio, and text—often involve complex, non-linear patterns. Activation functions allow the network to model these complex relationships."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc4e0bb3",
   "metadata": {},
   "source": [
    "**The Pooling Step**\n",
    "\n",
    "This step is mainly for reducing dimensionality by reducung the size of the feature map (the result map from the covolutional step) while keeping the important information in the newly reduced version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8745d6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can connect the output of the first convolutional layer to the pooling layer by using the following code:\n",
    "pooling_layer_1 = tf.layers.max_pooling2d(\n",
    "  inputs=conv_layer_1,\n",
    "  pool_size=[2, 2],\n",
    "  strides=2)\n",
    "# The pooling layer reduces the spatial dimensions of the input, which helps to reduce the number of parameters and computation in the network.\n",
    "\n",
    "# The pooling layer receives the input from the convolutional step with the following shape:\n",
    "[batch_size, image_height, image_width, channels]\n",
    "\n",
    "# that is.........\n",
    "\n",
    "[batch_size, 28, 28, 20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ff88fe",
   "metadata": {},
   "source": [
    "The output of the pooling operation will have the following shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b59e5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "[batch_size, 14, 14, 20]\n",
    "# The output shape of the pooling layer is determined by the input shape, the pool size, and the stride."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17649029",
   "metadata": {},
   "source": [
    "In this example, we have reduced the xsize of the output of the convolution step by 50%. This step is very useful because it keeps only the important information and \n",
    "it also reduces the models complexity and hence avoids overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a076a5f",
   "metadata": {},
   "source": [
    "**FULLY CONNECTED LAYER**\n",
    "\n",
    "After stacking up a bunch of convolution and pooling steps, we follow them with a fully conncted layer where we feed the extracted high level features that we got from the input image to this fully connceted layer to use them nd do the actual classification based on these features.\n",
    "\n",
    "For example, in the case of the digit classification task, we can follow the convolution and ppoling step with a fully connected layer that has 1024 neurons and ReLU activation to perform the actual classification. This fully connected layer accepts the input in the following format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006f7164",
   "metadata": {},
   "outputs": [],
   "source": [
    "[batch_size, features]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e28e719",
   "metadata": {},
   "source": [
    "So we need to flatten or reshape our input feature map from pool_layer2to match this format. We use the following line of code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03c4167",
   "metadata": {},
   "outputs": [],
   "source": [
    "pool1_flat = tf.reshape(pooling_layer_1, [-1, 14 * 14 * 20])\n",
    "# The flattening step converts the 2D feature maps into a 1D vector, which can be fed into the fully connected layers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfcb22fa",
   "metadata": {},
   "source": [
    "In this reshape function, we have used -1 to indicate that the batch size will be dynamically determined and each example from the pooling_layer_1 output will have a width of 14, and a height of 14 with 20 channels each.\n",
    "\n",
    "So the final output of the reshape operation will be "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a69608",
   "metadata": {},
   "outputs": [],
   "source": [
    "[batch_size, 3136]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a747003",
   "metadata": {},
   "source": [
    "Then finally, we use the dense() function of tensorflow to define our fully connected layer with the required number of neurons (units) and the final activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b8fc7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_layer_1 = tf.layers.dense(\n",
    "  inputs=pool1_flat,\n",
    "  units=1024,\n",
    "  activation=tf.nn.relu)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d99ca0",
   "metadata": {},
   "source": [
    "Logits Layer\n",
    "\n",
    "This is for the logits layer\n",
    "\n",
    "tommorroww\n",
    "\n",
    "try again"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
