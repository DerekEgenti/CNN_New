{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 1. Step-by-step CNN Code (in Python with TensorFlow/Keras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1. Load dataset (CIFAR-10: 60,000 images in 10 classes)\n",
    "(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()\n",
    "\n",
    "# Normalize pixel values to between 0 and 1\n",
    "train_images, test_images = train_images / 255.0, test_images / 255.0\n",
    "\n",
    "# We normalize pixel values to between 0 and 1 to \n",
    "\n",
    "#Makes training more stable.\n",
    "\n",
    "#Helps the network learn faster and more effectively.\n",
    "\n",
    "#Reduces the risk of exploding/vanishing gradients.\n",
    "\n",
    "#Ensures consistency across different datasets or models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. CNN Model Architecture with Explanations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Create the CNN model\n",
    "model = models.Sequential()\n",
    "\n",
    "# --- Convolutional Layer 1 ---\n",
    "# Applies 32 filters of size 3x3\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
    "# --- Pooling Layer 1 ---\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# --- Convolutional Layer 2 ---\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "# --- Pooling Layer 2 ---\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# --- Convolutional Layer 3 ---\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "\n",
    "# --- Flattening the 3D output to 1D ---\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "# --- Fully Connected Layer ---\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "\n",
    "# --- Output Layer: 10 neurons for 10 classes ---\n",
    "#model.add(layers.Dense(10))\n",
    "model.add(layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Concepts Explained\n",
    "\n",
    "\n",
    "ğŸ”¹ Filter/Kernel:\n",
    "A small matrix (like 3x3 or 5x5) that slides over the input image to extract features like edges, textures, etc. Think of it as a detector.\n",
    "\n",
    "ğŸ”¹ Stride:\n",
    "The number of pixels the filter moves at each step. A stride of 1 means move one pixel at a time.\n",
    "\n",
    "ğŸ”¹ Padding:\n",
    "Used to control the spatial size of the output. If you want to keep the size the same as input, you use 'same' padding (adds zeros around the border).\n",
    "\n",
    "ğŸ”¹ Convolutional Layer:\n",
    "Applies multiple filters across the image to produce feature maps, each highlighting specific features.\n",
    "\n",
    "ğŸ”¹ Pooling Layer:\n",
    "Reduces the dimensions (downsampling) while keeping the most important info. Common is MaxPooling, which takes the max value in a window (e.g., 2x2).\n",
    "\n",
    "ğŸ”¹ Abstraction:\n",
    "As the network goes deeper, it learns increasingly abstract features. Early layers might detect edges, later ones can detect complex patterns like faces or objects.\n",
    "\n",
    "ğŸ”¹ Fully Connected Layers:\n",
    "Standard neural network layers that interpret the high-level features and map them to class scores.\n",
    "\n",
    "ğŸ”¹ Output Layer:\n",
    "Final layer that outputs class scores (logits). Usually followed by Softmax for classification to interpret as probabilities.\n",
    "\n",
    "ğŸ”¹ Activation Function:\n",
    "An activation function is a mathematical function applied after each neuron (or filter output) to decide whether it should be \"activated\" (i.e., passed forward) or not.\n",
    "\n",
    "Uses\n",
    " Introduce Non-Linearity\n",
    "Without activation functions, neural networks are just linear transformations, no matter how many layers you stack.\n",
    "\n",
    "Real-world data is non-linear (images, speech, language), so we need non-linear activation functions to learn complex patterns.\n",
    "\n",
    " Control Information Flow\n",
    "They help the network decide which information is important.\n",
    "\n",
    "Some activations zero-out or squash less useful signals (e.g., ReLU zeros out negative values).\n",
    "\n",
    " Enable Learning of Complex Representations\n",
    "They help the network build hierarchical abstractions, e.g.:\n",
    "\n",
    "Early layers: detect edges\n",
    "\n",
    "Mid layers: detect shapes\n",
    "\n",
    "Late layers: detect faces or objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Training the CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Steps:\n",
    "Forward pass: Input image flows through the layers, generating predictions.\n",
    "\n",
    "Loss calculation: Difference between predicted and actual labels.\n",
    "\n",
    "Backpropagation: Gradients are calculated and used to update weights.\n",
    "\n",
    "Optimizer: Adam (Adaptive Moment Estimation) updates weights efficiently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Derek Egenti\\anaconda3\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\nn.py:717: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 20ms/step - accuracy: 0.3668 - loss: 1.7176 - val_accuracy: 0.5308 - val_loss: 1.3052\n",
      "Epoch 2/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 17ms/step - accuracy: 0.5808 - loss: 1.1658 - val_accuracy: 0.6194 - val_loss: 1.0780\n",
      "Epoch 3/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 16ms/step - accuracy: 0.6422 - loss: 1.0038 - val_accuracy: 0.6297 - val_loss: 1.0473\n",
      "Epoch 4/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 16ms/step - accuracy: 0.6799 - loss: 0.9063 - val_accuracy: 0.6744 - val_loss: 0.9574\n",
      "Epoch 5/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 16ms/step - accuracy: 0.7139 - loss: 0.8252 - val_accuracy: 0.6894 - val_loss: 0.9036\n",
      "Epoch 6/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 16ms/step - accuracy: 0.7363 - loss: 0.7620 - val_accuracy: 0.6801 - val_loss: 0.9421\n",
      "Epoch 7/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 17ms/step - accuracy: 0.7445 - loss: 0.7215 - val_accuracy: 0.7083 - val_loss: 0.8651\n",
      "Epoch 8/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 15ms/step - accuracy: 0.7664 - loss: 0.6706 - val_accuracy: 0.7036 - val_loss: 0.8672\n",
      "Epoch 9/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 16ms/step - accuracy: 0.7851 - loss: 0.6172 - val_accuracy: 0.7065 - val_loss: 0.8602\n",
      "Epoch 10/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 16ms/step - accuracy: 0.7964 - loss: 0.5721 - val_accuracy: 0.7125 - val_loss: 0.8862\n"
     ]
    }
   ],
   "source": [
    "# 3. Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# 4. Train the model\n",
    "history = model.fit(train_images, train_labels, epochs=10, \n",
    "                    validation_data=(test_images, test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Testing the CNN\n",
    "\n",
    "This checks how well the trained model generalizes to unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 2s - 8ms/step - accuracy: 0.7125 - loss: 0.8862\n",
      "\n",
      "Test accuracy: 0.7124999761581421\n"
     ]
    }
   ],
   "source": [
    "# 5. Evaluate the model on test data\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels, verbose=2)\n",
    "print(f'\\nTest accuracy: {test_acc}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
