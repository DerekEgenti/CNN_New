{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 1. Step-by-step CNN Code (in Python with TensorFlow/Keras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1. Load dataset (CIFAR-10: 60,000 images in 10 classes)\n",
    "(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()\n",
    "\n",
    "# Normalize pixel values to between 0 and 1\n",
    "train_images, test_images = train_images / 255.0, test_images / 255.0\n",
    "\n",
    "# We normalize pixel values to between 0 and 1 to \n",
    "\n",
    "#Makes training more stable.\n",
    "\n",
    "#Helps the network learn faster and more effectively.\n",
    "\n",
    "#Reduces the risk of exploding/vanishing gradients.\n",
    "\n",
    "#Ensures consistency across different datasets or models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. CNN Model Architecture with Explanations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Create the CNN model\n",
    "model = models.Sequential()\n",
    "\n",
    "# --- Convolutional Layer 1 ---\n",
    "# Applies 32 filters of size 3x3\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
    "# --- Pooling Layer 1 ---\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# --- Convolutional Layer 2 ---\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "# --- Pooling Layer 2 ---\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# --- Convolutional Layer 3 ---\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "\n",
    "# --- Flattening the 3D output to 1D ---\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "# --- Fully Connected Layer ---\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "\n",
    "# --- Output Layer: 10 neurons for 10 classes ---\n",
    "#model.add(layers.Dense(10))\n",
    "model.add(layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Concepts Explained\n",
    "\n",
    "\n",
    "🔹 Filter/Kernel:\n",
    "A small matrix (like 3x3 or 5x5) that slides over the input image to extract features like edges, textures, etc. Think of it as a detector.\n",
    "\n",
    "🔹 Stride:\n",
    "The number of pixels the filter moves at each step. A stride of 1 means move one pixel at a time.\n",
    "\n",
    "🔹 Padding:\n",
    "Used to control the spatial size of the output. If you want to keep the size the same as input, you use 'same' padding (adds zeros around the border).\n",
    "\n",
    "🔹 Convolutional Layer:\n",
    "Applies multiple filters across the image to produce feature maps, each highlighting specific features.\n",
    "\n",
    "🔹 Pooling Layer:\n",
    "Reduces the dimensions (downsampling) while keeping the most important info. Common is MaxPooling, which takes the max value in a window (e.g., 2x2).\n",
    "\n",
    "🔹 Abstraction:\n",
    "As the network goes deeper, it learns increasingly abstract features. Early layers might detect edges, later ones can detect complex patterns like faces or objects.\n",
    "\n",
    "🔹 Fully Connected Layers:\n",
    "Standard neural network layers that interpret the high-level features and map them to class scores.\n",
    "\n",
    "🔹 Output Layer:\n",
    "Final layer that outputs class scores (logits). Usually followed by Softmax for classification to interpret as probabilities.\n",
    "\n",
    "🔹 Activation Function:\n",
    "An activation function is a mathematical function applied after each neuron (or filter output) to decide whether it should be \"activated\" (i.e., passed forward) or not.\n",
    "\n",
    "Uses\n",
    " Introduce Non-Linearity\n",
    "Without activation functions, neural networks are just linear transformations, no matter how many layers you stack.\n",
    "\n",
    "Real-world data is non-linear (images, speech, language), so we need non-linear activation functions to learn complex patterns.\n",
    "\n",
    " Control Information Flow\n",
    "They help the network decide which information is important.\n",
    "\n",
    "Some activations zero-out or squash less useful signals (e.g., ReLU zeros out negative values).\n",
    "\n",
    " Enable Learning of Complex Representations\n",
    "They help the network build hierarchical abstractions, e.g.:\n",
    "\n",
    "Early layers: detect edges\n",
    "\n",
    "Mid layers: detect shapes\n",
    "\n",
    "Late layers: detect faces or objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Training the CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Steps:\n",
    "Forward pass: Input image flows through the layers, generating predictions.\n",
    "\n",
    "Loss calculation: Difference between predicted and actual labels.\n",
    "\n",
    "Backpropagation: Gradients are calculated and used to update weights.\n",
    "\n",
    "Optimizer: Adam (Adaptive Moment Estimation) updates weights efficiently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Derek Egenti\\anaconda3\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\nn.py:717: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 20ms/step - accuracy: 0.3668 - loss: 1.7176 - val_accuracy: 0.5308 - val_loss: 1.3052\n",
      "Epoch 2/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 17ms/step - accuracy: 0.5808 - loss: 1.1658 - val_accuracy: 0.6194 - val_loss: 1.0780\n",
      "Epoch 3/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 16ms/step - accuracy: 0.6422 - loss: 1.0038 - val_accuracy: 0.6297 - val_loss: 1.0473\n",
      "Epoch 4/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 16ms/step - accuracy: 0.6799 - loss: 0.9063 - val_accuracy: 0.6744 - val_loss: 0.9574\n",
      "Epoch 5/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 16ms/step - accuracy: 0.7139 - loss: 0.8252 - val_accuracy: 0.6894 - val_loss: 0.9036\n",
      "Epoch 6/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 16ms/step - accuracy: 0.7363 - loss: 0.7620 - val_accuracy: 0.6801 - val_loss: 0.9421\n",
      "Epoch 7/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 17ms/step - accuracy: 0.7445 - loss: 0.7215 - val_accuracy: 0.7083 - val_loss: 0.8651\n",
      "Epoch 8/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 15ms/step - accuracy: 0.7664 - loss: 0.6706 - val_accuracy: 0.7036 - val_loss: 0.8672\n",
      "Epoch 9/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 16ms/step - accuracy: 0.7851 - loss: 0.6172 - val_accuracy: 0.7065 - val_loss: 0.8602\n",
      "Epoch 10/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 16ms/step - accuracy: 0.7964 - loss: 0.5721 - val_accuracy: 0.7125 - val_loss: 0.8862\n"
     ]
    }
   ],
   "source": [
    "# 3. Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# 4. Train the model\n",
    "history = model.fit(train_images, train_labels, epochs=10, \n",
    "                    validation_data=(test_images, test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Testing the CNN\n",
    "\n",
    "This checks how well the trained model generalizes to unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 2s - 8ms/step - accuracy: 0.7125 - loss: 0.8862\n",
      "\n",
      "Test accuracy: 0.7124999761581421\n"
     ]
    }
   ],
   "source": [
    "# 5. Evaluate the model on test data\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels, verbose=2)\n",
    "print(f'\\nTest accuracy: {test_acc}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
